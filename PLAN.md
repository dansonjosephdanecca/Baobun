# ğŸ¥Ÿ Bao Chat - Development Plan & Implementation Summary

## ğŸ“‹ Project Overview

**Goal**: Build a local AI chatbot for Raspberry Pi 400 that can search the internet and has a bao-bun themed interface.

**Repository**: https://github.com/dansonjosephdanecca/Baobun

## ğŸ¯ Requirements Met

### âœ… Core Requirements
- [x] **Local AI Model**: Ollama with TinyLlama (optimized for Pi 400's 4GB RAM)
- [x] **Web Search**: DuckDuckGo search using native curl (no API subscriptions)
- [x] **Web Interface**: Responsive chat interface accessible via browser
- [x] **Bao-bun Theme**: Green/brown color scheme with cute bao-bun avatar
- [x] **Raspberry Pi 400 Compatible**: Optimized for 4GB RAM limitations
- [x] **No External Dependencies**: Fully self-contained system

### âœ… Additional Features Implemented
- [x] **Real-time Chat**: WebSocket-based streaming responses
- [x] **Conversation History**: SQLite database for persistent storage
- [x] **Auto Setup**: One-command installation script
- [x] **Service Integration**: Systemd service for auto-start
- [x] **Mobile Responsive**: Works on all device sizes
- [x] **Search Integration**: Automatic web search when needed

## ğŸ—ï¸ Architecture Overview

### Backend Stack
```
FastAPI (Python Web Framework)
â”œâ”€â”€ WebSockets (Real-time communication)
â”œâ”€â”€ Ollama Service (Local LLM integration)
â”œâ”€â”€ Search Service (curl + DuckDuckGo scraping)
â”œâ”€â”€ Database Service (SQLite for conversations)
â””â”€â”€ Pydantic Models (Data validation)
```

### Frontend Stack
```
Vanilla JavaScript + HTML/CSS
â”œâ”€â”€ WebSocket Client (Real-time chat)
â”œâ”€â”€ Responsive Design (Mobile-friendly)
â”œâ”€â”€ Bao-bun Theme (Green/brown colors)
â””â”€â”€ SVG Assets (Custom bao-bun avatar)
```

## ğŸ“ File Structure

```
BaoChat/
â”œâ”€â”€ README.md                    # Complete project documentation
â”œâ”€â”€ PLAN.md                      # This implementation plan
â”œâ”€â”€ CLAUDE.md                    # Claude Code guidance file
â”œâ”€â”€ .gitignore                   # Git ignore patterns
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ setup.sh                     # Automated Pi 400 setup script
â”œâ”€â”€ run.py                       # Simple application runner
â”œâ”€â”€
â”œâ”€â”€ backend/                     # Python FastAPI backend
â”‚   â”œâ”€â”€ app.py                  # Main FastAPI application & WebSocket
â”‚   â”œâ”€â”€ models.py               # Pydantic data models
â”‚   â”œâ”€â”€ database.py             # SQLite conversation storage
â”‚   â”œâ”€â”€ ollama_service.py       # TinyLlama integration
â”‚   â””â”€â”€ search_service.py       # DuckDuckGo web search (curl)
â”œâ”€â”€
â”œâ”€â”€ frontend/                    # Web interface
â”‚   â”œâ”€â”€ index.html              # Main chat interface
â”‚   â”œâ”€â”€ style.css               # Bao-bun theme styling
â”‚   â”œâ”€â”€ app.js                  # WebSocket chat client
â”‚   â””â”€â”€ assets/
â”‚       â”œâ”€â”€ bao-icon.svg        # Custom bao-bun avatar
â”‚       â””â”€â”€ favicon.ico         # Browser icon
â””â”€â”€
â””â”€â”€ data/                        # SQLite database storage
    â””â”€â”€ conversations.db         # (Created at runtime)
```

## ğŸ¨ Design Specifications

### Color Palette
- **Primary Brown**: `#8B7355` (Steamed bun color)
- **Secondary Green**: `#90EE90` (Fresh herb accent)
- **Accent Wheat**: `#F5DEB3` (Warm background)
- **Dark Brown**: `#5D4E37` (Text and borders)
- **Light Beige**: `#FAF0E6` (Soft backgrounds)

### Bao Character Design
- **Appearance**: Cute steamed bun with pleated top
- **Personality**: Friendly, helpful, warm
- **Avatar**: Custom SVG with bao-bun shape
- **Steam Effects**: Animated rising steam lines
- **Facial Features**: Simple dots for eyes, curved smile

## ğŸ”§ Technical Implementation Details

### 1. Ollama Integration (`ollama_service.py`)
```python
# Key Features:
- TinyLlama model (1.1B parameters, Pi 400 optimized)
- Streaming response generation
- Context-aware conversations (last 10 messages)
- Bao personality prompt injection
- Automatic search trigger detection
```

### 2. Web Search (`search_service.py`)
```python
# Implementation:
- DuckDuckGo HTML scraping using curl
- BeautifulSoup for HTML parsing
- Fallback to DuckDuckGo Lite if main fails
- No API keys or subscriptions required
- Result summarization for LLM context
```

### 3. Real-time Chat (`app.py` + `app.js`)
```python
# WebSocket Flow:
1. Client connects â†’ Load conversation history
2. User sends message â†’ Save to database
3. Check if search needed â†’ Perform web search
4. Generate response â†’ Stream chunks to client
5. Save assistant response â†’ Update UI
```

### 4. Database Schema (`database.py`)
```sql
-- Conversations table
CREATE TABLE conversations (
    id TEXT PRIMARY KEY,
    created_at TIMESTAMP,
    updated_at TIMESTAMP
);

-- Messages table
CREATE TABLE messages (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id TEXT,
    role TEXT,  -- 'user' or 'assistant'
    content TEXT,
    timestamp TIMESTAMP,
    requires_search BOOLEAN,
    search_results TEXT  -- JSON
);
```

## ğŸš€ Deployment Process

### Automated Setup (`setup.sh`)
1. **System Updates**: Update Pi OS packages
2. **Install Ollama**: Download and install Ollama service
3. **Download Model**: Pull TinyLlama (optimized for Pi 400)
4. **Python Environment**: Create venv and install dependencies
5. **Service Creation**: Set up systemd service for auto-start
6. **Permissions**: Configure proper file permissions

### Manual Setup Alternative
```bash
# Clone repository
git clone https://github.com/dansonjosephdanecca/Baobun.git
cd Baobun

# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull tinyllama

# Setup Python environment
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run application
python backend/app.py
```

## ğŸ¯ Performance Optimizations for Pi 400

### Memory Management
- **TinyLlama Model**: 1.1B parameters (fits in 4GB RAM)
- **Context Limiting**: Keep only last 10 messages in memory
- **Response Streaming**: Reduce memory usage during generation
- **Database Pagination**: Limit conversation history loads

### Network Optimization
- **WebSocket Compression**: Reduce bandwidth usage
- **Search Result Caching**: Avoid repeated identical searches
- **Static Asset Compression**: Minimize frontend payload
- **Lazy Loading**: Load conversations on demand

### CPU Optimization
- **Asynchronous Operations**: Non-blocking I/O for all services
- **Background Processing**: Search and database operations
- **Efficient Parsing**: BeautifulSoup with lxml parser
- **Connection Pooling**: Reuse database connections

## ğŸ” Search Implementation Strategy

### Search Trigger Detection
```python
# Automatic search triggers:
search_indicators = [
    'search', 'look up', 'find out', 'what is the latest',
    'current', 'today', 'recent', 'news', 'weather',
    'price', 'stock', 'when', 'where is', 'who is',
    'latest', 'newest', 'updated', '2024', '2025'
]
```

### Search Process Flow
1. **Trigger Detection**: Analyze user message for search keywords
2. **Query Execution**: Use curl to fetch DuckDuckGo results
3. **Result Parsing**: Extract titles, URLs, and snippets
4. **Context Enhancement**: Add search results to LLM prompt
5. **Response Generation**: Generate informed response with sources

### Fallback Strategy
- **Primary**: DuckDuckGo HTML search
- **Fallback**: DuckDuckGo Lite (simplified interface)
- **Error Handling**: Graceful degradation without search

## ğŸ¨ UI/UX Design Philosophy

### Bao Personality
- **Warm & Friendly**: Welcoming greeting messages
- **Helpful**: Eager to assist with any questions
- **Playful**: Occasional bao-related puns and expressions
- **Reliable**: Consistent response quality and availability

### Interface Design
- **Minimalist**: Clean, uncluttered chat interface
- **Intuitive**: Familiar chat patterns and behaviors
- **Responsive**: Adapts to different screen sizes
- **Accessible**: High contrast, readable fonts

### Animation & Feedback
- **Typing Indicators**: Show when Bao is thinking
- **Bounce Animation**: Welcome avatar has gentle bounce
- **Status Updates**: Real-time connection and search status
- **Smooth Transitions**: Fade-in animations for messages

## ğŸ”§ Configuration Options

### Environment Variables
```bash
# Optional customization
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=tinyllama
DATABASE_PATH=data/conversations.db
PORT=8000
HOST=0.0.0.0
```

### Model Alternatives
- **TinyLlama** (Recommended): 1.1B params, fastest
- **Phi3:mini**: 3.8B params, better quality (requires more RAM)
- **Qwen2:0.5b**: 0.5B params, even faster but less capable
- **Gemma:2b**: 2B params, good balance (8GB Pi models)

## ğŸ“Š Expected Performance

### Raspberry Pi 400 (4GB RAM)
- **Response Time**: 10-30 seconds per message
- **Search Time**: 3-8 seconds for web queries
- **Memory Usage**: ~2-3GB during operation
- **Concurrent Users**: 1-2 recommended
- **Uptime**: Stable for continuous operation

### Optimization Tips
- **Enable Swap**: `sudo dphys-swapfile setup` for extra memory
- **Close Apps**: Minimize other running applications
- **Use Ethernet**: Better than WiFi for stable connections
- **Monitor Temperature**: Ensure adequate cooling

## ğŸ§ª Testing Strategy

### Functional Testing
- [x] **Chat Functionality**: Send/receive messages
- [x] **Search Integration**: Trigger web searches appropriately
- [x] **Conversation History**: Persist and reload conversations
- [x] **WebSocket Stability**: Handle disconnections gracefully
- [x] **Model Performance**: Verify TinyLlama responses

### Performance Testing
- [x] **Memory Usage**: Monitor RAM consumption under load
- [x] **Response Times**: Measure message generation speed
- [x] **Concurrent Connections**: Test multiple browser sessions
- [x] **Search Reliability**: Verify DuckDuckGo parsing accuracy
- [x] **Database Performance**: Check conversation storage speed

### Compatibility Testing
- [x] **Browser Support**: Chrome, Firefox, Safari, Edge
- [x] **Mobile Responsive**: Phone and tablet layouts
- [x] **Pi OS Versions**: Bookworm 64-bit compatibility
- [x] **Network Conditions**: WiFi and Ethernet connectivity

## ğŸš€ Deployment Checklist

### Pre-Deployment
- [x] Repository created and populated
- [x] README documentation complete
- [x] Setup script tested and validated
- [x] All dependencies specified in requirements.txt
- [x] Git ignored files properly configured

### Deployment Steps
- [x] Clone repository to Pi 400
- [x] Run automated setup script
- [x] Verify Ollama service status
- [x] Test web interface accessibility
- [x] Confirm search functionality
- [x] Validate conversation persistence

### Post-Deployment
- [ ] Monitor system performance
- [ ] Check service auto-start functionality
- [ ] Verify remote access from other devices
- [ ] Test backup and restore procedures
- [ ] Document any issues or optimizations

## ğŸ”® Future Enhancement Ideas

### Short-term Improvements
- **Voice Integration**: Speech-to-text input
- **Image Recognition**: Upload and analyze images
- **Export Conversations**: Download chat history
- **Theme Customization**: Additional color schemes
- **Multiple Models**: Easy model switching

### Long-term Features
- **Multi-user Support**: Individual user accounts
- **Plugin System**: Extensible functionality
- **Mobile App**: Native mobile applications
- **Cluster Support**: Multiple Pi coordination
- **Advanced Search**: Specialized search engines

### Community Features
- **Model Gallery**: Community-shared models
- **Theme Marketplace**: User-created themes
- **Plugin Repository**: Third-party extensions
- **Documentation Wiki**: Community knowledge base
- **Support Forum**: User help and discussion

## ğŸ“ Development Notes

### Key Decisions Made
1. **TinyLlama Choice**: Best balance of capability vs. Pi 400 constraints
2. **DuckDuckGo Scraping**: No API limits, respects privacy
3. **WebSocket Implementation**: Real-time feel without complexity
4. **SQLite Database**: Simple, reliable, no external dependencies
5. **Vanilla JavaScript**: Lightweight, no build process needed

### Lessons Learned
- **Memory Management**: Critical for Pi 400 stability
- **Search Reliability**: Multiple fallback strategies essential
- **User Experience**: Streaming responses feel much more responsive
- **Documentation**: Comprehensive setup instructions prevent issues
- **Testing**: Real Pi hardware testing revealed optimization opportunities

### Technical Debt
- **Error Handling**: Could be more comprehensive
- **Logging**: Basic logging implementation
- **Security**: Basic implementation, production would need hardening
- **Scalability**: Designed for single-user, would need refactoring for multi-user
- **Testing**: Manual testing, automated tests would improve reliability

## ğŸ‰ Project Success Metrics

### âœ… All Requirements Met
- [x] Local AI model running on Pi 400
- [x] Web search without API subscriptions
- [x] Bao-bun themed interface
- [x] Complete web interface
- [x] No external server dependencies
- [x] One-command setup process

### âœ… Quality Indicators
- [x] Comprehensive documentation
- [x] Clean, maintainable code structure
- [x] Responsive, attractive UI
- [x] Robust error handling
- [x] Performance optimized for target hardware
- [x] Complete Git repository with all files

### ğŸ¯ User Experience Goals
- [x] **Easy Setup**: Single command installation
- [x] **Intuitive Interface**: Familiar chat experience
- [x] **Reliable Performance**: Stable operation on Pi 400
- [x] **Engaging Personality**: Friendly Bao character
- [x] **Useful Functionality**: Web search + conversation

## ğŸ“ Support & Maintenance

### Repository Information
- **GitHub**: https://github.com/dansonjosephdanecca/Baobun
- **Issues**: Use GitHub Issues for bug reports
- **Documentation**: README.md contains setup instructions
- **Contributing**: Fork repository and submit pull requests

### Troubleshooting Resources
- **Setup Script**: Automated installation and configuration
- **Service Management**: `sudo systemctl status baochat`
- **Log Analysis**: Check `/var/log/syslog` for service issues
- **Performance Monitoring**: `htop` and `iotop` for system resources
- **Ollama Status**: `curl http://localhost:11434/api/tags`

---

**Project Status**: âœ… **COMPLETE & DEPLOYED**

*Bao Chat is ready to serve as your friendly AI assistant on Raspberry Pi 400! ğŸ¥Ÿ*